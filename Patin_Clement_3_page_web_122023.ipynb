{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5297d59-0f93-4a43-88b4-2542aa20740a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ad0374-9243-411c-9c36-7f14318786f9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (891856097.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[2], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    print(8\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "print(8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6a9466-ec79-45ae-b1b1-d60202cb14b3",
   "metadata": {},
   "source": [
    "# AMÉLIORER LE PRODUIT IA DE VOTRE START-UP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46baadec-88e6-402f-a243-89aa6f85d6c3",
   "metadata": {},
   "source": [
    "<img src=\"logoAvisRestau.png\" alt=\"logoAvisRestau\" width=\"300\" class=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242c642f-6572-4b4e-946e-ad3c645b1c9e",
   "metadata": {},
   "source": [
    "# SYNTHESE GRAPHIQUE DES RESULTATS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc37228-02fd-46fe-9558-770154b93000",
   "metadata": {},
   "source": [
    "L'objectif ici est de **synthétiser** les principaux résultats de l'analyse :\n",
    "- des **commentaires négatifs** pour détecter les **sujets d'insatisfaction**\n",
    "- des **photos** pour détecter leur **catégorie**\n",
    "\n",
    "(Pour plus de détail et pour parcourir les différentes étapes ayant permis d'atteindre ces résultats, se référer au notebook principal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1833b5-bda2-4f94-bcdf-003249e1555f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "# custom functions\n",
    "import myFunctions as mf\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "# LDA\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "# pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "# file and directory management\n",
    "import os\n",
    "# to make saves\n",
    "from joblib import dump, load  \n",
    "\n",
    "# data viz\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "# image annotations\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "from matplotlib.colors import ListedColormap, to_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a456e1-792c-4df9-a627-8d69e6750de3",
   "metadata": {},
   "source": [
    "# PARTIE I - ANALYSER LES COMMENTAIRES NÉGATIFS POUR DÉTECTER LES DIFFÉRENTS SUJETS D’INSATISFACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b5f4ae-01bc-4e01-a66a-6b629536d014",
   "metadata": {},
   "source": [
    "## NLP - Méthode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a572ee-9eaa-4e5b-8280-01490a66a5a7",
   "metadata": {},
   "source": [
    "L'objectif **final** est de détecter les sujets de mécontentement dans les avis qui seront postés sur **Avis Restau**. Le but ici n'est pas de réaliser ce projet entièrement **mais de tester sa faisabilité**. Pour cela nous avons la chance de disposer d'un jeu de données existant disponible sur la plateforme **Yelp**. \n",
    "\n",
    "Nous réaliserons donc notre études préliminaire sur ce dataset :\n",
    "- Nous réaliserons les étapes préalables à l'entraînement d'une algorithme de détection de sujets :\n",
    "    - sélectionner quelques milliers de **commentaires négatifs**\n",
    "    - **pré-traiter** ces données :\n",
    "        - mettre en minuscule,\n",
    "        - tokeniser,\n",
    "        - normaliser les mots via une lemmatisation,\n",
    "        - etc.\n",
    "    - création du **dictionnaire** et représentation de nos reviews en vecteurs **bag-of-words**\n",
    "    - adapter la **pondération** des mots grâce à un **TF-IDF**\n",
    "- Nous testerons alors la faisabilité sur ce petit échantillons :\n",
    "    - utiliser une **technique de réduction de dimension** de type **topic-modeling** pour extraire nos sujets d'insatisfaction sous-jacents de notre corpus. Nous utiliserons ici le `Latent Dirichlet Allocation (LDA)`\n",
    "    - évaluer notre réduction afin de choisir le bon hyperparamètre `num_topics`\n",
    "- Enfin nous tâcherons de visualiser nos topics afin d'en détecter les mots-clés. Pour cela nous utiliserons 2 librairies :\n",
    "    - `wordcloud`\n",
    "    - `pyLDAvis`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe62073-457b-4f39-9721-e02485d8180e",
   "metadata": {},
   "source": [
    "## NLP - Nos commentaires et leur nettoyage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e577efb5-0f3a-42e6-a6cf-28bf6a9aec22",
   "metadata": {},
   "source": [
    "Étapes du preprocessing :\n",
    "- **charger** un **échantillon** de reviews\n",
    "- mettre en **minuscules**\n",
    "- **supprimer** les **url**\n",
    "- **supprimer** les **séquences d'échappement**\n",
    "- **corriger** les mots avec des **caractères répétés**\n",
    "- cleaning général :\n",
    "    - **supprimer** les **ponctuations**\n",
    "    - **supprimer** les **stopwords**\n",
    "    - **supprimer** les **stopwords spécifiques** métier\n",
    "    - **supprimer** les **nombres** et les nombres écrits en lettres\n",
    "    - **filtrer** sur les **POS** (en ne gardant que les adjectifs et noms)\n",
    "    - **normaliser** les mots (ici : **lemmatisation**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a937c0a7-d289-461f-af16-03055df1fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load existing .joblib\n",
    "rev = load(\"mySaves/rev/rev.joblib\")\n",
    "rev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d935fe77-291b-4309-a213-8c4906ba5860",
   "metadata": {},
   "source": [
    "## NLP - Dictionnaire, BOW et TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0ce83a-5d99-4329-8bdf-f1886873eede",
   "metadata": {},
   "source": [
    "Nota : Par rapport à l'exemple ci-dessus, nous avons intégré **plus de commentaires : 60000**.\n",
    "\n",
    "Étapes de traitement :\n",
    "- création **dictionnaire**\n",
    "- filtre sur la **fréquence** pour les mots rare et et pour les mots fréquents\n",
    "- conversion des documents en **bag-of-words**\n",
    "- pondération des documents par **TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd8b9f0-fd92-46e3-b766-92bb07363e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load existing .joblib\n",
    "tfidf_vector = load(\"mySaves/nlpDictAndVector/tfidf_vector.joblib\")\n",
    "dictionary = load(\"mySaves/nlpDictAndVector/dictionary.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c60a13-fd42-46b5-bfae-ad97fcc103c8",
   "metadata": {},
   "source": [
    "Exemple de document après le traitement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04caa30b-11df-4789-9c40-5fc54a597071",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tfidf_vector[16])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f3b23d-94cc-472b-bd08-9f8ab792a6ae",
   "metadata": {},
   "source": [
    "## NLP - Latent Dirichlet Allocation et visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd5444f-a0cf-40c8-a606-e9ea010d0be9",
   "metadata": {},
   "source": [
    "**Choix du nombre de topics** basé sur le **score de cohérence** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc480366-dd5a-46b0-914c-52de04657f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"coherencesPlot.joblib\" in os.listdir(\"mySaves/coherencesPlot\") :\n",
    "    # load existing .joblib\n",
    "    load(\"mySaves/coherencesPlot/coherencesPlot.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e9429f-2329-4207-b6b2-26cb375f8ffd",
   "metadata": {},
   "source": [
    "Il n'y a **pas vraiment de pic** ... Nous observons néanmoins **une chute** de cohérence **après 5 topics**. Nous allons regarder ce que cela donne pour **3, 4 et 5 topics** :\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e693e93b-ae57-4bbb-b660-fdce356c5876",
   "metadata": {},
   "source": [
    "### NLP - LDA - 3 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74e7e09-544b-4128-bf3b-9f2168ab4bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the LDA model \n",
    "model = LdaModel(\n",
    "    corpus=tfidf_vector,\n",
    "    num_topics=3,\n",
    "    id2word=dictionary,\n",
    "    random_state=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b681dda3-0558-4699-a4be-7c4596a53940",
   "metadata": {},
   "source": [
    "Vue `wordcloud` et score de cohérence :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7735c52-743b-4e08-b5df-aa7ee2542198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use custom function wordCloudAndCoherence to display 1 wordcloud for each topic and compute coherence_score\n",
    "mf.wordCloudAndCoherence(model=model, corpus=tfidf_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a5c085-c649-47c9-ace4-cd033393b2ef",
   "metadata": {},
   "source": [
    "Les limites d'une telle visualisation :\n",
    "- ne nous permet **pas vraiment de comprendre le degré de différence entre les topics**\n",
    "- apporte du **biais aléatoire dans l'interprétation de l'importance des mots** (orientation, position, couleur)\n",
    "- ne nous permet pas de visualiser l'**importance relative des topics**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93346586-0531-46a5-ab0d-d97d37c358dc",
   "metadata": {},
   "source": [
    "Voyons ce que cela donne avec `PyLDAvis` :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5042c3b-b8a3-4df4-a284-555cc8ac2eca",
   "metadata": {},
   "source": [
    "`pyLDAvis` est une librairie spécialisée permettant de :\n",
    "-  avoir une vue d'ensemble d'un modèle de topic modeling\n",
    "-  explorer en détail chaque topic\n",
    "-  explorer en détail chaque mot par rapport aux topics\n",
    "\n",
    "Il est composé de plusieurs parties :\n",
    "- ***Intertopic Distance Map*** :\n",
    "    - représentation 2D **des topics dans l'espace des probabilités de mots dans les topics (matrice topics/mots issue du modèle de LDA)**. Cette **réduction** de dimension 2D est issue d'un **MDS** (multidimensional scaling)\n",
    "    - la représentation de chaque topic dans cet espace réduit **permet ainsi d'apprécier les distances qui les séparent les uns des autres** dans l'espace plus large, et donc **s'ils sont bien différents**\n",
    "    - la taille de chaque topic est elle liée à l'**espace des probabilités des topics dans les documents (matrice documents/topics issue du modèle LDA)**. La **somme des probabilités** sur tous les documents de chaque topic permet de définir sa taille. Elle représente donc la **prédominance du topic dans le corpus**\n",
    "- liste des mots les plus importants :\n",
    "    - **sans spécifier** un topic : ***Top-30 Most Salient Terms*** :\n",
    "        - mots classés selon la *saliency* : liée à la fréquence globale de chaque mot dans le corpus.\n",
    "        - **barres bleus** : fréquences **à l'échelle du corpus**\n",
    "    - **en sélectionnant** un topic : ***Top-30 Most Relevant Terms for Topic n*** :\n",
    "        - mots classés selon la *relevance* : liée à la probabilité de chaque mot dans un topic particulier. Ce classement évolue en fonction du paramètre λ :\n",
    "            - **λ tend vers 1** : la *relevance* met plus en avant **les mots les plus présents au sein du topic**\n",
    "            - **λ tend vers 0** : la *relevance* normalise cette probabilité du mot pour ce topic avec la probabilité du mot au global dans le corpus. On voit alors apparaître **non pas les mots forcément les plus présents, mais les mots les plus distinctifs du topic analysé**\n",
    "        - **barres rouges** : fréquences estimées **au sein du topic**\n",
    "    - il est **aussi possible de sélectionner un mot** en particulier : les **tailles** des topics de l'**Intertopic Distance Map** représentent alors **seulement la répartion de ce mot choisi aux sein des topics**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93eb188-745a-4c75-b9e1-6e94aebcae4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the \"prepare\" function \n",
    "vis_data  = gensimvis.prepare(\n",
    "    topic_model=model,\n",
    "    corpus=tfidf_vector,\n",
    "    dictionary=dictionary\n",
    ")\n",
    "# display\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14356757-bd5f-460d-9198-4034ab0781be",
   "metadata": {},
   "source": [
    "Les **3 sujets** de mécontentement :\n",
    "- le **comportement du personnel et le temps d'attente**, avec des mots comme *table, server, minute, hour, rude, manager, experience, incorrect, customer, hostess, staff*, etc.\n",
    "- le **rapport qualité / prix**, avec des mots comme *flavor, bland, dry, taste, price, portion, small*, etc.\n",
    "- la **livraison**, avec des mots comme *delivery, order, hour, service, slow, min, minute, driver, phone, refund*, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f037d8-ce5e-40e0-a8b5-1b33241f6fac",
   "metadata": {},
   "source": [
    "### NLP - LDA - 4 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d752da-7dc3-4ee4-ab65-6d3c5a10802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the LDA model \n",
    "model = LdaModel(\n",
    "    corpus=tfidf_vector,\n",
    "    num_topics=4,\n",
    "    id2word=dictionary,\n",
    "    random_state=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f81e5b7-e935-40a2-a038-f349b40e7d53",
   "metadata": {},
   "source": [
    "Vue `wordcloud` et score de cohérence :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c35ce6-1d08-4195-9b51-97df421445fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use custom function wordCloudAndCoherence to display 1 wordcloud for each topic and compute coherence_score\n",
    "mf.wordCloudAndCoherence(model=model, corpus=tfidf_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b494e14-5569-4026-aca8-24e976e5bb98",
   "metadata": {},
   "source": [
    "Vue `PyLDAvis` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab48579d-0567-4582-9f3b-275f2d53e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the \"prepare\" function \n",
    "vis_data  = gensimvis.prepare(\n",
    "    topic_model=model,\n",
    "    corpus=tfidf_vector,\n",
    "    dictionary=dictionary\n",
    ")\n",
    "# display\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4029e98-62ef-4444-8622-88b9bda27ece",
   "metadata": {},
   "source": [
    "les **4 sujets** se distinguent un peu plus :\n",
    "- le **comportement du personnel et le temps d'attente**, avec des mots comme *minute, reservation, order, manager, rude, hour, employee, server, waitress, hostess, service, time, busy, attitude*, etc.\n",
    "- la **qualité du plat et son prix**, avec des mots comme *flavor, dry, bland, salty, quality, taste, poisonning, soggy, price, portion, small*, etc.\n",
    "- l'**hygiène**, avec des mots comme *dirty, flour, filthy, clean, hair, glove, mask, fly, bathroom, cleanliness, cockroach, rat, restroom, toilet, disgusting, bug*, etc.\n",
    "- la **livraison**, avec des mots comme *driver, delivery, uber, masked, order, drive, time, hour, slow, cold*,etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfeeafc-9eeb-45c9-9341-155f0f3511f8",
   "metadata": {},
   "source": [
    "### NLP - LDA - 5 topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fc642c-43d5-4d25-adf7-bab84fe36b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the LDA model \n",
    "model = LdaModel(\n",
    "    corpus=tfidf_vector,\n",
    "    num_topics=5,\n",
    "    id2word=dictionary,\n",
    "    random_state=16\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db81765e-8de2-4a21-b69c-4dc8aaba0f75",
   "metadata": {},
   "source": [
    "Vue `wordcloud` et score de cohérence :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a9339b-6005-4e77-be81-2a65b545518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use custom function wordCloudAndCoherence to display 1 wordcloud for each topic and compute coherence_score\n",
    "mf.wordCloudAndCoherence(model=model, corpus=tfidf_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86ad68b-d8ba-4207-b723-f7bea3c29b48",
   "metadata": {},
   "source": [
    "Vue `PyLDAvis` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c2d73c-e9b4-4390-b110-175d543cfb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the \"prepare\" function \n",
    "vis_data  = gensimvis.prepare(\n",
    "    topic_model=model,\n",
    "    corpus=tfidf_vector,\n",
    "    dictionary=dictionary\n",
    ")\n",
    "# display\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e985f7e-1529-4928-a41b-18d60e6e9125",
   "metadata": {},
   "source": [
    "Les **5 sujets** de mécontentement :\n",
    "- l'**ambiance** avec des mots comme *table, reservation, music, loud, party, birthday, noisy, dance*, etc.\n",
    "- l'**attitude du personnel et le temps d'attente**, avec des mots comme *table, delivery, understaffed, reservation, minute, order, manager, rude, hour, employee, waitress, service, time, busy, attitude*, etc.\n",
    "- **2 sujets très proches sur la nourriture**, avec des mots en commun comme *flavor, soggy, dry, taste*, etc. :\n",
    "    -  l'un un peu plus axé sur la **qualité du plat et son prix**, avec des mots comme *portion, price, small, quality, taste*, etc.\n",
    "    -  l'autre se concentrant plus exclusivement sur la nourriture\n",
    "- l'**hygiène**, avec des mots comme *dirty, filthy, bathroom, glove, floor, mask, health, restroom, toilet, disgusting, rat, cleaning, roach, hair*, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdda7b70-9e06-4787-8b05-2cfa87e372ad",
   "metadata": {},
   "source": [
    "## NLP - Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631eeb59-0b4c-4882-acea-3510122a23b2",
   "metadata": {},
   "source": [
    "Il est **difficile de conclure sur le nombre idéal de topics** :\n",
    "- se contenter de 3 met de côté l'hygiène\n",
    "- conserver 4 topics est intéressant car les sujets sont clairs, avec l'hygiène qui se rajoute,\n",
    "- enfin avec 5 topics nous avons réussi à obtenir un sujet différent avec l'ambiance, mais la livraison disparaît et le rapport qualité/prix se divise en 2 sous-thèmes pas très clairs...\n",
    "\n",
    "Nous pouvons néanmoins **conclure sur le faisabilité du projet** :\n",
    "- le fait d'**ajouter plus de commentaires et d'affiner la préparation des données** a permis de **trouver de vrais sujets de mécontentement**,\n",
    "- il est donc tout à fait possible :\n",
    "    - que l'utilisation de **toute la base de données** nous permette de faire disparaître les limitations que nous avons observé\n",
    "    - qu'une **recherche plus poussée des meilleures paramètres** de notre pipeline (`gridsearchCV`, `BayesSearchCV`, etc.) permette d'améliorer le modèle:\n",
    "        - filtrage,\n",
    "        - liste de stopwords,\n",
    "        - le nombre de topics,\n",
    "        - les autres hyper-paramètres du modèle (`alpha` et `eta` notamment, qui conditionne le côté plus ou moins *lisse* des distributions de chaque document en topics et de chaque topic en mots)\n",
    "- **cependant** il faut noter que :\n",
    "    - nous avons dû ajouter **\"à la main\"** beaucoup de *stopwords* spécifiques... A voir si ce procédé peut d'une quelconque manière être évité...\n",
    "    - après quelques essais il s'avère que les **thèmes détectés par le modèle sont instables** (notamment en fonction de la liste des *stopwords* spécifiques)\n",
    "\n",
    "Il serait intéressant, dans le cadre de la poursuite du projet, de tester d'autres modèles (`LSA`? `BERTopic`? autre ?)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2aa2f73-11bc-4909-9f6b-8077e33679fb",
   "metadata": {},
   "source": [
    "# PARTIE II.A - ANALYSER LES PHOTOS POUR DÉTERMINER LES CATÉGORIES DES PHOTOS - SIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d799fea-0a0a-4648-b141-dc4e938adc21",
   "metadata": {},
   "source": [
    "## CV-SIFT - Méthode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3145c6af-c287-4d0a-9c53-cb34471175b7",
   "metadata": {},
   "source": [
    "Nous avons la chance que les photos Yelp soient **déjà labellisées** : L'objectif **final** est d'entraîner un algorithme de **classification supervisée** sur celles-ci afin d'utiliser le modèle ultérieurement **sur les photos qui seront publiées sur Avis Restau**.\n",
    "\n",
    "Le but ici n'est pas de réaliser ce projet entièrement. L'objectif **préliminaire** est d'**analyser** les photos pour vérifier la faisabilité : \n",
    "- Nous réaliserons donc toutes les étapes préalables à l'entraînement d'un algorithme de classification :\n",
    "    - réaliser le **pré-traitement** sur N images\n",
    "    - **extraire les features** (nous utiliserons le **SIFT**) pour obtenir les descripteurs de nos N images\n",
    "    - création des bag-of-visual-words :\n",
    "        - **trouver les \"visual words\" grâce à un algorithme KMeans** appliqué sur l'ensemble des descripteurs trouvés\n",
    "        - construire l'**histogramme de chaque image** en fonction de ce dictionnaire de \"visual-words\"\n",
    "        - contruire ainsi notre **matrice des \"bag-of-visual-words\"**, de taille N images X taille dictionnaire\n",
    "    - adapter la **pondération** des visual-words grâce à un **TF-IDF**<br>\n",
    "    \n",
    "    **... mais au lieu de réaliser ce travail sur un très grand nombre de photos (avec un split préalable en train/test set, etc.), nous ne prendrons que quelques photos de chaque catégorie.**<br>\n",
    "\n",
    "- Nous testerons alors la **faisabilité sur ce petit échantillon** avec un **clustering KMeans** avec **K = le nombre de labels** pour vérifier que nos features peuvent bien regrouper nos labels :\n",
    "    - réduction de **dimension préalable** via une ACP\n",
    "    - appliquer le KMeans\n",
    "    - effectuer une mesure de **similarité ARI**\n",
    "    - analyser les catégories les mieux regroupées (via une **matrice de confusion** entre les catégories et les clusters prédits)<br><br>\n",
    "\n",
    "\n",
    "- Nous tâcherons également de visualiser nos N images dans cet espace des features pour **analyser si les catégories/labels fournies ressortent** :\n",
    "    - utilisation du même espace réduit par l'ACP\n",
    "    - réduction de dimension par **T-SNE**, idéal pour représenter des données en grande dimension\n",
    "    - visualisation :\n",
    "        - des catégories\n",
    "        - des clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62a2542-5015-4781-b2c3-7b9b578fa516",
   "metadata": {},
   "source": [
    "## CV-SIFT - Nos image et leur traitement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3b69b7-08d7-472c-9328-7df87ef2a9c8",
   "metadata": {},
   "source": [
    "Étapes du preprocessing :\n",
    "- **charger** un **échantillon** d'images\n",
    "- **mettre** en nuance de **gris**\n",
    "- **égalisation** d'**histogramme**\n",
    "- **filtre gaussien**\n",
    "- **extraire** les features **descripteurs SIFT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24838b39-59f3-4618-acc8-412c52000782",
   "metadata": {},
   "source": [
    "Nous pouvons regarder ce que cela donne visuellement :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebfae6e-7e1c-4e2a-8c39-7ac473299366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load existing .joblib\n",
    "examplesPhotoDict = load(\"mySaves/examplesPhotoDict/examplesPhotoDict.joblib\")\n",
    "\n",
    "# create a figure\n",
    "fig, axs = plt.subplots(2,5, figsize=(14,6))\n",
    "\n",
    "# choose a category example\n",
    "cat = \"drink\"\n",
    "\n",
    "# plot the two images stored in the dict for this category, for each preprocessing step\n",
    "for i,phase in enumerate(['raw', 'gray', 'equal', 'gaussian', 'keypoints']) :\n",
    "    for j,img in enumerate(examplesPhotoDict[phase][cat]) :\n",
    "        # plot\n",
    "        # handle grayscale\n",
    "        if len(img.shape) == 2 :\n",
    "            axs[j,i].imshow(img, cmap='gray',vmin=0,vmax=255)\n",
    "        else :\n",
    "            axs[j,i].imshow(img)\n",
    "\n",
    "        # set anchor\n",
    "        axs[j,i].set_anchor(\"N\")\n",
    "        # remove axis\n",
    "        axs[j,i].axis(False)\n",
    "        # title on top axes \n",
    "        if j==0 :\n",
    "            axs[j,i].set_title(phase)\n",
    "\n",
    "# sup title\n",
    "fig.suptitle(\"Photo cleaning steps\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded262b0-37e9-4f3c-90b6-d69651f325f3",
   "metadata": {},
   "source": [
    "## CV-SIFT - Dictionnaire, Bag-of-Visual-Words, TF-IDF, PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ff1eb-a47d-4308-acfe-1052bb47bdba",
   "metadata": {},
   "source": [
    "Étapes de traitement :\n",
    "- Création d'un **dictionnaire de visual words** :\n",
    "    - rassemblement de tous les descripteurs des images\n",
    "    - utilisation d'un algorithme de clustering (`MiniBatchKMeans`) : chaque centroïde de cluster correspond à un *visual word*\n",
    "- Création **matrice des Bag-of-Visual-Words** :\n",
    "    - pour chaque descripteur de chaque image, appliquer le modèle de clustering (dictionnaire) pour attibuer le visual word correspondant\n",
    "    - pour chaque image, compter le nombre d'occurences de chaque *visual word* présent\n",
    "    - intégrer ces histogrammes à une matrice (nombre d'images X nombre de *visual words*)\n",
    "- Appliquer la pondération **TF-IDF**\n",
    "- Appliquer une analyse en composantes principales **PCA** pour :\n",
    "    - réduire le nombre de dimension (*curse of dimensionality*)\n",
    "    - faciliter le travail du futur modèle (temps et mémoire)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3afe283-cdc0-4fd5-8371-981c9e288a99",
   "metadata": {},
   "source": [
    "Nous avons alors un dataframe comportant une ligne par image et une colonne par composante principale :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d5c3bb-b04d-4218-ab94-3ac382854a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load existing .joblib\n",
    "siftFeatures = load(\"mySaves/siftFeatures/siftFeatures.joblib\")\n",
    "siftFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aa4eca-425b-4def-9320-5ffac3e78565",
   "metadata": {},
   "source": [
    "## CV-SIFT - Clustering - Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22c4273-7d45-44d0-ba0d-1c68cc9d2e89",
   "metadata": {},
   "source": [
    "Nous allons maintenant vérifier s'il serait **faisable** de labelliser automatiquement nos photos. Pour cela nous n'allons pas utiliser d'algorithme de classification supervisée (pour rappel nous avons fait le choix d'utiliser peu de données), mais un **modèle de clustering**. Cela nous permettra d' **analyser, à ce stade préliminaire, si les features que nous venons de créer permettent de regrouper nos catégories dans des clusters**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a82787-36a6-4af7-8d48-c150b0b664de",
   "metadata": {},
   "source": [
    "Étapes de l'étude de faisabilité :\n",
    "- **algorithme de clustering** avec, pour rappel, **K = le nombre catégories de photo**\n",
    "- calcul de l'**ARI** entre les labels des clusters et les catégories\n",
    "- **projection** de nos données **en 2D** grâce à un **TSNE**\n",
    "- **représentation** des clusters et des vraies catégories **sur cet espace**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3e6e7d-adc1-4b91-9138-655003a222fc",
   "metadata": {},
   "source": [
    "L'**ARI** pour cette méthode SIFT n'est pas très bon : **< 0.15 ...** Notre clustering n'est pas une réussite. On le remarque assez bien sur la projection T-SNE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006124a2-ebce-4c4b-bb77-8e313a1f7d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use existing .joblib\n",
    "load(\"mySaves/figures/figSIFTscatter.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18efdeb9-a132-49b4-be71-a49e740854c5",
   "metadata": {},
   "source": [
    "La seule classe intéressante en termes de résultat est **\"menu\"**. On peut vérifier également cela en remplaçant quelques points par leurs images respectives :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaa7f00-52ec-44f4-aff4-baf2bc56a658",
   "metadata": {},
   "source": [
    "<img src=\"mySaves/figures/figSIFTphotos.png\" alt=\"figSIFTphotos\" class=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bdd8c0-d223-44e5-9e15-576abfc4dc80",
   "metadata": {},
   "source": [
    "Le **SIFT ne nous permet pas vraiment de conclure positivement** quant à l'opportunité de développer un modèle de classification supervisée... Essayons maintenant avec du Transfer Learning :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a94e79-7f6a-45aa-a43d-e1f63b4ebc2a",
   "metadata": {},
   "source": [
    "# PARTIE II.B - ANALYSER LES PHOTOS POUR DÉTERMINER LES CATÉGORIES DES PHOTOS - TRANSFER LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcf1fc5-ba25-4172-b61a-6bd9f55aae84",
   "metadata": {},
   "source": [
    "## CV-TL - Utiliser un VGG16 pré-entraîné comme un extracteur de features autonome"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feeb769-f9b2-4f8e-b60a-ec788394ac53",
   "metadata": {},
   "source": [
    "Ici les étapes de traitement diffèrent un peu : \n",
    "\n",
    "- Charger nos photos et **les préparer** pour le `VGG16` :\n",
    "    - les charger à la taille **224 x 224**\n",
    "    - les convertir en **array**\n",
    "    - les **rassembler** en un seul array\n",
    "    - les convertir en **BGR**\n",
    "    - **centrer** chaque canal de couleur\n",
    "- Utiliser un `VGG16` **déjà entraîné** comme un **extracteur de features** :\n",
    "    - **retirer la dernière couche fully-connected** (celle contenant la fonction d'activation Softmax nous donnant normalement nos scores par classe)\n",
    "    - **se servir de la sortie de la couche précédente** comme **features**\n",
    "- Appliquer également une réduction de dimensions par `PCA`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675f4e80-1441-4999-8772-f657aa699438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load existing .joblib\n",
    "vgg16Features = load(\"mySaves/transferLearningFeatures/reducedVGG16featuresDf.joblib\")\n",
    "vgg16Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095496d7-9730-41ac-b8bd-e5dc207d068f",
   "metadata": {},
   "source": [
    "## CV-TL - Clustering - Kmeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec8d78-216a-4368-aa0a-42d20060afd3",
   "metadata": {},
   "source": [
    "L'**ARI** pour cette méthode Transfer Learning est bien meilleur : **> 0.70 ...** On le remarque assez bien sur la projection T-SNE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd99d96-1ec0-49bc-8fe4-67caff015bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use existing .joblib\n",
    "load(\"mySaves/figures/figTLscatter.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86bb82b-72b5-4194-a74b-303a26fd46af",
   "metadata": {},
   "source": [
    "La **correspondance est bonne**. On peut vérifier également cela en remplaçant quelques points par leurs images respectives :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b3bbf6-f321-40d7-819f-f64cafb00668",
   "metadata": {},
   "source": [
    "<img src=\"mySaves/figures/figTLphotos.png\" alt=\"figTLphotos\" class=\"center\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a21dce9-ef38-4bf4-b6e6-18efaadde11c",
   "metadata": {},
   "source": [
    "**Le VGG16 en tant qu'extracteur de features donne de bien meilleurs résultats.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e32477-21cf-4e0d-8fbf-e896b460666e",
   "metadata": {},
   "source": [
    "On peut **conclure** qu'il serait **opportun de poursuivre le projet** avec le **développement d'un modèle de classification supervisée** (avec bien plus de photos)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envProject6",
   "language": "python",
   "name": "envproject6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
